{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e60f31",
   "metadata": {},
   "source": [
    "## Loading required libraries \n",
    "- Required Libraries:\n",
    "    - tensorflow > 2\n",
    "    - numpy\n",
    "    - pandas\n",
    "    - sklearn\n",
    "- Run all cells ( cell -> Run All )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b321a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7882ad8",
   "metadata": {},
   "source": [
    "## Load the data in required format\n",
    "- Specify the base directories of train and test data\n",
    "- The function **load_dataset** takes the parameter **dataset_type** to decide which dataset to load (train or test)\n",
    "- The function checks the directory for records, assigns the label to the record as the parent directory (1: wheat, 0: rapeseed) \n",
    "- Convert the categorical features in the input data into one hot encodings\n",
    "- Append each sample to collection of records \n",
    "- Return the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54f56177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset \n",
    "\n",
    "train_dir = '/projects/AAI/SS22/crop-classification/TimeSen2Crop-SmallSet/train'\n",
    "test_dir = '/projects/AAI/SS22/crop-classification/TimeSen2Crop-SmallSet/test'\n",
    "\n",
    "def load_dataset(dataset_type = None):\n",
    "    train_x, train_y, test_x = list(), list(), list()\n",
    "    if(dataset_type in ('train', 'test')):\n",
    "        load_dir = None\n",
    "        if(dataset_type == 'train'):\n",
    "            load_dir = train_dir\n",
    "            for f in os.listdir(load_dir):\n",
    "                if(f == 'wheat'):\n",
    "                    x_dir = os.path.join(load_dir, f)\n",
    "                    for x_sample in os.listdir(x_dir):\n",
    "                        X = read_csv(os.path.join(x_dir, x_sample))\n",
    "                        flag_dummies = pd.get_dummies(X.iloc[:, -1])\n",
    "                        #print(flag_dummies.shape)\n",
    "                        #X.iloc[:,-1] = flag_dummies\n",
    "                        train_x.append(X)\n",
    "                        train_y.append(1)\n",
    "                else:\n",
    "                    x_dir = os.path.join(load_dir, f)\n",
    "                    for x_sample in os.listdir(x_dir):\n",
    "                        X = read_csv(os.path.join(x_dir, x_sample))\n",
    "                        #flag_dummies = pd.get_dummies(X.iloc[:,-1])\n",
    "                        #X.iloc[:,-1] = flag_dummies\n",
    "                        train_x.append(X)\n",
    "                        train_y.append(0)\n",
    "            return np.array(train_x), np.array(train_y)\n",
    "        else:\n",
    "            load_dir = test_dir\n",
    "            for f in os.listdir(load_dir):\n",
    "                X = read_csv(os.path.join(load_dir, f))\n",
    "                test_x.append(X)\n",
    "            return np.array(test_x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9631c67",
   "metadata": {},
   "source": [
    "## Perform preprocessing , Train and Validation Split\n",
    "- Cateogical variable, **flag** among various features of input records contains different inputs across samples.\n",
    "- Collect all the unique values accross inputs, store them into a list and perform one-hot encoding on the list.\n",
    "- Store the one hot encodings in a dictionary with corresponding flag key. (lookup dictionary)\n",
    "- Training data is split into training set and validation set.\n",
    "- The function **preprocess_data** performs following actions:\n",
    "    - For Each sample in the data provided,\n",
    "        - the sample is divided into variables containing numerical and categorical features.\n",
    "        - The numerical part is standardized, The categorical part is converted to one-hot representation by refering to the lookup dictionary.\n",
    "        - The processed parts are concatenated and the original sample is updated with the processed sample.\n",
    "- preprocess the training data, validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43681d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    for i in range(len(data)):\n",
    "        sample = data[i]\n",
    "        sample_n = sample[:, :-1] #all the variables with continous values\n",
    "        \n",
    "        stdizer = StandardScaler()\n",
    "        stdizer = stdizer.fit(sample_n)\n",
    "        sample_n = stdizer.transform(sample_n)\n",
    "        \n",
    "        sample_c = sample[:, -1] # categorical values\n",
    "        \n",
    "\n",
    "        sample_c_oh = np.array([all_flags_dict[j] for j in sample_c])\n",
    "        data[i] = np.concatenate([sample_n, sample_c_oh], axis = 1)\n",
    "        \n",
    "        \n",
    "    data = np.array(data)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91a2e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 23, 13)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, trainY = load_dataset(dataset_type='train')\n",
    "all_flags = set([j for i in trainX for j in i[:, -1]])\n",
    "all_flags = np.array(list(all_flags))\n",
    "all_flags_oh = np.array(pd.get_dummies(all_flags))\n",
    "all_flags_dict = {key: value for (key, value) in zip(all_flags, all_flags_oh)}\n",
    "trainX = list(trainX)\n",
    "test_x = list(test_x)\n",
    "trainY = pd.get_dummies(trainY)\n",
    "\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(trainX, trainY, test_size=0.1, random_state=42)\n",
    "\n",
    "train_x_pp = preprocess_data(train_x)\n",
    "validation_x_pp = preprocess_data(validation_x)\n",
    "\n",
    "train_x_pp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a42fb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x[198]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad7dfe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = load_dataset(dataset_type='train')\n",
    "test_x = load_dataset(dataset_type='test')\n",
    "\n",
    "all_flags = set([j for i in trainX for j in i[:, -1]])\n",
    "all_flags = np.array(list(all_flags))\n",
    "\n",
    "all_flags_oh = np.array(pd.get_dummies(all_flags))\n",
    "all_flags_dict = {key: value for (key, value) in zip(all_flags, all_flags_oh)}\n",
    "\n",
    "trainX = list(trainX)\n",
    "test_x = list(test_x)\n",
    "trainY = pd.get_dummies(trainY)\n",
    "\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(trainX, trainY, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    for i in range(len(data)):\n",
    "        sample = data[i]\n",
    "        sample_n = sample[:, :-1] #all the variables with continous values\n",
    "        \n",
    "        stdizer = StandardScaler()\n",
    "        stdizer = stdizer.fit(sample_n)\n",
    "        sample_n = stdizer.transform(sample_n)\n",
    "        \n",
    "        sample_c = sample[:, -1] # categorical values\n",
    "        \n",
    "\n",
    "        sample_c_oh = np.array([all_flags_dict[j] for j in sample_c])\n",
    "        #data[i] = np.concatenate([sample_n, sample_c_oh], axis = 1)\n",
    "        data[i] = sample_n\n",
    "        \n",
    "        \n",
    "    data = np.array(data)\n",
    "    return data\n",
    "    \n",
    "train_x_pp = preprocess_data(train_x)\n",
    "validation_x_pp = preprocess_data(validation_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b06a45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e02d7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 9)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_timesteps, n_features = train_x_pp.shape[1], train_x_pp.shape[2]\n",
    "n_timesteps, n_features "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ece9d69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0906a83c",
   "metadata": {},
   "source": [
    "## Predictive Model\n",
    "- As the data contains **time series sequence**, the problem can be identified as **time series classification**.\n",
    "- Since **RNNs**, work well for time series applications, the model was built using **LSTMs**.\n",
    "- The model is essentially a **Bidirectional Stacked LSTM Neural Network**\n",
    "- Network architecture is as follows:\n",
    "    - input - (time steps, features)\n",
    "    - Bidirectional LSTM layer with 70 LSTM units.\n",
    "    - Dropout layer with p = 0.5.\n",
    "    - Batch Normalization Layer\n",
    "    - Bidirectional LSTM layer with 70 LSTM units.\n",
    "    - Dropout layer with p = 0.5.\n",
    "    - Batch Normalization Layer\n",
    "    - Fully connected layer with 100 neurons\n",
    "    - Relu activation layer.\n",
    "    - output - Fully connected layer with 2 neurons for classification with Softmax activation function.\n",
    "- Loss function: Categorical Cross Entropy Loss\n",
    "- Optimizer : Adam\n",
    "- Although it is a binary classification problem, 2 units in output layer were used with softmax instead of one unit simply because of the simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54e27707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(lstm_units, train_x, train_y):\n",
    "    n_timesteps, n_features = train_x.shape[1], train_x.shape[2]\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(lstm_units, return_sequences=True), input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(lstm_units)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43601057",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "- The model is trained with following hyper parameters:\n",
    "    - epochs : 20, batch size: 32\n",
    "    \n",
    "- We perform training until we get the desired accuracy and we set a loop threshold as well, to prevent infinite loop.\n",
    "\n",
    "- The **predict_crop_type** function is used to output the crop type given the dataset and trained model as parameters.\n",
    "\n",
    "- The model is evaulated based on **accuracy**, **precision**, **recall** and **f1-score** metrics on the validation dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4bb9fc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 23, 9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b61228df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 640us/step - loss: 0.3309 - accuracy: 0.8696\n",
      "1/1 [==============================] - 0s 778us/step - loss: 0.0813 - accuracy: 0.9565\n",
      "Final validation accuracy 0.95652174949646\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_model(70, train_x_pp, train_y)\n",
    "accuracy = 0\n",
    "loop_count = 0\n",
    "loop_threshold = 10\n",
    "accuracy_threshold = 0.95\n",
    "while(accuracy < accuracy_threshold and loop_count < loop_threshold):\n",
    "    lstm_model.fit(train_x_pp, train_y, epochs=20, batch_size=32, verbose=0)\n",
    "    _, temp_acc = lstm_model.evaluate(validation_x_pp, validation_y, verbose=1)\n",
    "    accuracy = temp_acc\n",
    "    loop_count += 1\n",
    "    \n",
    "\n",
    "print(f'Final validation accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a000c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_crop_type(x, model):\n",
    "    predictions = list()\n",
    "    predictions.append(model.predict(x))\n",
    "    return predictions\n",
    "\n",
    "crop_type = {0:'rapeseed', 1:'wheat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "476fe1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.92, recall: 0.92 f1 score: 0.96\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_crop_type(validation_x_pp, lstm_model)\n",
    "predictions = np.argmax(predictions, axis = 2)[0]\n",
    "predictions_labels = np.array([str(crop_type[i]) for i in predictions])\n",
    "\n",
    "validation_y_np = validation_y.to_numpy()\n",
    "ground_truth = np.argmax(validation_y_np, axis= 1)\n",
    "ground_truth_labels = np.array([str(crop_type[i]) for i in ground_truth])\n",
    "\n",
    "precision = precision_score(ground_truth, predictions)\n",
    "recall = recall_score(predictions, ground_truth)\n",
    "f1_score = f1_score(predictions, ground_truth)\n",
    "\n",
    "print(f'precision: {np.round(precision, decimals=2)}, recall: {np.round(recall, decimals=2)} f1 score: {np.round(f1_score, decimals=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4672e9",
   "metadata": {},
   "source": [
    "## Comparison of predicted labels and ground truth labels\n",
    "- The prediction is performed on validation data\n",
    "- The table below shows the predictions compared to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df3c4bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predcitions</th>\n",
       "      <th>ground truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wheat</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rapeseed</td>\n",
       "      <td>rapeseed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predcitions ground truth\n",
       "0     rapeseed     rapeseed\n",
       "1     rapeseed     rapeseed\n",
       "2        wheat        wheat\n",
       "3     rapeseed     rapeseed\n",
       "4     rapeseed     rapeseed\n",
       "5     rapeseed     rapeseed\n",
       "6        wheat        wheat\n",
       "7        wheat        wheat\n",
       "8        wheat        wheat\n",
       "9        wheat        wheat\n",
       "10    rapeseed     rapeseed\n",
       "11    rapeseed     rapeseed\n",
       "12       wheat     rapeseed\n",
       "13    rapeseed     rapeseed\n",
       "14       wheat        wheat\n",
       "15       wheat        wheat\n",
       "16       wheat        wheat\n",
       "17       wheat        wheat\n",
       "18       wheat        wheat\n",
       "19    rapeseed     rapeseed\n",
       "20       wheat        wheat\n",
       "21       wheat        wheat\n",
       "22    rapeseed     rapeseed"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_matrix = np.stack([predictions_labels, ground_truth_labels], axis = 1)\n",
    "comparison_matrix = pd.DataFrame(comparison_matrix, columns=['predcitions', 'ground truth'])\n",
    "comparison_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f589edb",
   "metadata": {},
   "source": [
    "## Prediction on the test data set\n",
    "- preprocessing is performed on the test data\n",
    "- Model predicts the outcomes\n",
    "- The table shows the predictions for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db7a0ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.84651347,  0.82190026,  0.72522181, ...,  0.96373357,\n",
       "          1.57808217,  1.70592206],\n",
       "        [-0.45729739, -0.46955542, -0.51922234, ..., -0.12977125,\n",
       "         -0.40608103, -0.26084409],\n",
       "        [-0.49535224, -0.49767129, -0.50511712, ..., -0.61390676,\n",
       "         -0.16394866, -0.25792893],\n",
       "        ...,\n",
       "        [-0.35697098, -0.31819831, -0.24894818, ..., -0.51769055,\n",
       "          0.76160852,  0.83234361],\n",
       "        [-0.34313286, -0.29804861, -0.22164776, ..., -0.5426355 ,\n",
       "          0.81201833,  1.01211226],\n",
       "        [-0.34053821, -0.31304374, -0.24849317, ..., -0.5920163 ,\n",
       "          0.78226828,  1.03349015]],\n",
       "\n",
       "       [[-0.46032361, -0.47623552, -0.51781801, ..., -0.67099601,\n",
       "         -0.38695342, -0.41191963],\n",
       "        [-0.46922351, -0.50332209, -0.52550737, ..., -0.73967127,\n",
       "         -0.39045899, -0.41101785],\n",
       "        [ 2.71550735,  2.53167902,  2.31855251, ...,  1.84817951,\n",
       "          2.10900895,  2.23662246],\n",
       "        ...,\n",
       "        [-0.34778286, -0.30164137, -0.2229478 , ..., -0.33086787,\n",
       "          0.33729633,  0.29147255],\n",
       "        [-0.35438602, -0.29413545, -0.32023491, ..., -0.06498326,\n",
       "          0.23563494,  0.09398166],\n",
       "        [-0.41697245, -0.37833226, -0.47435641, ..., -0.15639559,\n",
       "         -0.10791044, -0.2829644 ]],\n",
       "\n",
       "       [[-0.51533707, -0.54062516, -0.58033819, ..., -0.61085141,\n",
       "         -0.48783732, -0.48960343],\n",
       "        [-0.51486287, -0.57252269, -0.60038944, ..., -1.02199936,\n",
       "         -0.7631652 , -0.63895196],\n",
       "        [ 0.50657459,  0.32883985,  0.18845628, ...,  0.13055296,\n",
       "          0.83356388,  0.80057514],\n",
       "        ...,\n",
       "        [-0.3166452 , -0.29676337, -0.22528425, ..., -0.34567314,\n",
       "          0.52630142,  0.16560301],\n",
       "        [-0.2402982 , -0.13881914, -0.01352343, ..., -0.53543374,\n",
       "          0.58153961,  0.63580999],\n",
       "        [-0.28250244, -0.18820887, -0.14165585, ..., -0.45758324,\n",
       "          0.46502155,  0.49802393]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.47577824, -0.54951112, -0.46868538, ..., -0.79150324,\n",
       "         -0.22805339,  0.06413377],\n",
       "        [-0.43165888, -0.53118489, -0.47663164, ..., -0.91536495,\n",
       "         -0.47323934, -0.27186428],\n",
       "        [-0.3362832 , -0.43250518, -0.43557596, ..., -0.99355265,\n",
       "         -0.40537537, -0.32158597],\n",
       "        ...,\n",
       "        [-0.08129923,  0.02001175,  0.08424187, ...,  0.29306084,\n",
       "          1.55611223,  1.36744459],\n",
       "        [-0.10984706,  0.02142146,  0.1054319 , ..., -0.33863387,\n",
       "          0.66402942,  0.95761737],\n",
       "        [-0.1805678 , -0.1061573 , -0.04885798, ..., -0.42378879,\n",
       "          0.27326431,  0.51464236]],\n",
       "\n",
       "       [[-0.46227526, -0.47847571, -0.55203779, ..., -0.3408991 ,\n",
       "         -0.35447195, -0.67693478],\n",
       "        [-0.45628325, -0.48058727, -0.52775708, ..., -0.68222758,\n",
       "         -0.40515923, -0.57479185],\n",
       "        [-0.40385312, -0.49536822, -0.51998725, ..., -1.18527045,\n",
       "         -0.99651089, -0.94141199],\n",
       "        ...,\n",
       "        [-0.28051748, -0.27154248, -0.13829448, ..., -0.32793726,\n",
       "          1.53655367,  1.28749251],\n",
       "        [-0.18764125, -0.10578474, -0.00523619, ..., -0.47668981,\n",
       "          0.941303  ,  1.33491601],\n",
       "        [-0.26603677, -0.19763776, -0.18637029, ..., -0.37176063,\n",
       "          0.62938124,  0.76765799]],\n",
       "\n",
       "       [[-0.47929533, -0.4870116 , -0.55970255, ..., -0.01409985,\n",
       "         -0.36370542, -0.58386601],\n",
       "        [-0.46151972, -0.46466555, -0.52665371, ..., -0.15698294,\n",
       "         -0.34631048, -0.51235106],\n",
       "        [-0.48279217, -0.55187721, -0.58671362, ..., -0.92718701,\n",
       "         -0.89830978, -0.87866652],\n",
       "        ...,\n",
       "        [-0.28609484, -0.24741231, -0.14659205, ..., -0.4158582 ,\n",
       "          0.28686518,  0.45707381],\n",
       "        [-0.31028133, -0.22630771, -0.20506308, ..., -0.24247198,\n",
       "          0.22540307,  0.30212475],\n",
       "        [-0.40731868, -0.34269337, -0.49582931, ...,  0.0545322 ,\n",
       "         -0.27267192, -0.47977203]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_pp = preprocess_data(test_x)\n",
    "test_x_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75a88aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.0508592e-03, 9.9894911e-01],\n",
      "       [1.0477438e-02, 9.8952252e-01],\n",
      "       [1.6227259e-03, 9.9837720e-01],\n",
      "       [5.6860312e-03, 9.9431396e-01],\n",
      "       [3.3585823e-03, 9.9664140e-01],\n",
      "       [4.6494088e-04, 9.9953508e-01],\n",
      "       [5.5279462e-03, 9.9447203e-01],\n",
      "       [2.0823538e-02, 9.7917652e-01],\n",
      "       [4.2195231e-01, 5.7804769e-01],\n",
      "       [1.0973314e-02, 9.8902673e-01]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.csv</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample Predicted Label\n",
       "0  10.csv           wheat\n",
       "1   8.csv           wheat\n",
       "2   5.csv           wheat\n",
       "3   9.csv           wheat\n",
       "4   6.csv           wheat\n",
       "5   3.csv           wheat\n",
       "6   1.csv           wheat\n",
       "7   2.csv           wheat\n",
       "8   7.csv           wheat\n",
       "9   4.csv           wheat"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test = predict_crop_type(test_x_pp, lstm_model)\n",
    "print(predictions_test)\n",
    "predictions_test = np.argmax(predictions_test, axis = 2)[0]\n",
    "predictions_test_labels = np.array([str(crop_type[i]) for i in predictions_test])\n",
    "\n",
    "file_names_test = np.array(os.listdir(test_dir))\n",
    "prediction_table = np.stack([file_names_test, predictions_test_labels], axis = 1)\n",
    "prediction_table_df = pd.DataFrame(prediction_table, columns=['Sample', 'Predicted Label'])\n",
    "prediction_table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a639962",
   "metadata": {},
   "source": [
    "## Since almost all of the samples are predicted as ***wheat***, we can assume that the test data belongs to ***wheat*** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a71a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
